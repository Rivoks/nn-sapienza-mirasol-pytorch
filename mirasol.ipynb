{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mirasol3B - Project report\n",
    "### Author: YAZID BOUHRIA 2124866\n",
    "\n",
    "I provide in this project an implementation of the model Mirasol presented in the paper [MIRASOL3B: A MULTIMODAL AUTOREGRESSIVE MODEL FOR TIME-ALIGNED AND CONTEXTUAL MODALITIES](https://arxiv.org/pdf/2311.05698.pdf).\n",
    "\n",
    "The Mirasol method is an approach for integrating and processing multimodal data, such as audio, video and text, for comprehension and content generation tasks. The implementation focuses on transforming multimodal inputs into latent representations using specific encoders, then combining them via a combination module. Textual context processing is carried out using cross-attention to integrate contextual information. An autoregressive decoder is used to generate predictions based on the combined representations. The aim is to enable the machine to understand and generate content by capturing the nuances of different input modalities.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "The implementation that I propose includes several key components for processing and generating content from multimodal data (audio, video and text):\n",
    "- `RandomData` generates random data for training. \n",
    "- `CombinerModel` integrates audio and video representations. \n",
    "- `AudioExtractor` and `VideoExtractor` extract features from audio and video inputs respectively. \n",
    "- `ContextAutoregressiveModel` and `TemporalAutoregressiveModel` process textual context and generate predictions respectively. \n",
    "- `MirasolModel` gather entire process from feature extraction to text generation.\n",
    "\n",
    "I've deliberately ignored the aspect of segmenting video and audio inputs into timechunks to get my model working on small inputs first.\n",
    "\n",
    "I thought I'd have time to integrate them later, but that didn't happen because of the difficulties I had implementing this project.\n",
    "\n",
    "Concerning the dataset, I decided to go on a random generated dataset in order to focus on the neural network building. After that, I tried to implement a Dataset based on samples from the _MSRVTT-QA_ dataset, as suggested in the paper, but my training had some issues with it (mostly because of missing input data segmentation...).\n",
    "\n",
    "I propose to dive-in the implementation and to explain how components are working\n",
    "\n",
    "### Datasets\n",
    "#### RandomDataset\n",
    "The RandomData class in PyTorch creates a dataset for generating random multimodal data, including audio, video, and textual context, along with random target labels for each instance. It's designed to simulate real-world data for training and testing multimodal machine learning models, providing a customizable number of samples (n). Each sample comprises random tensors representing audio features, video frames, contextual information, and target labels, facilitating the development and testing of models without requiring actual data.\n",
    "\n",
    "#### CustomVideoDataset\n",
    "This provide a dataset from the _MSRVTT_ dataset by loading video and audio data. This class extracts and processes video and audio features, including normalizing video inputs and converting audio to a specified sample size. I also converted associated textual information (questions and answers from annotations) into a usable format for the model, such as ASCII tensors, facilitating multimodal learning tasks.\n",
    "\n",
    "\n",
    "### Mirasol components\n",
    "\n",
    "#### VideoExtractor\n",
    "This class is designed to process video data by extracting interesting features using a pretrained neural network: the R3D-18 model from torchvision.models. It modifies the original architecture by removing the final classification layer, making it suitable for feature extraction rather than classification. This allows the extracted features to be used as input to other models of Mirasol that require a condensed representation of video content. I wrote it with the help of ChatGPT.\n",
    "\n",
    "#### AudioExtractor\n",
    "This class transforms audio waveforms into Mel Spectrogram representations. This process involves converting the raw audio signal into a set of coefficients that represent the power spectrum of the audio within various Mel scale frequency bands. \n",
    "The Mel scale is designed to mimic the human ear's response more closely than the linearly-spaced frequency bands used in the standard spectrogram. This makes Mel Spectrograms particularly useful since it captures important audio characteristics in a format that's easier for Mirasol to process and understand.\n",
    "\n",
    "#### Combiner\n",
    "As written in the paper, this model aim to integrate and process multi-modal data inputs using a Transformer encoder architecture. \n",
    "It first projects the concatenated features of different modalities (like audio and video) to to the define model dimension `model_dim` using a linear projection. \n",
    "This is crucial because it allows for the uniform processing of heterogeneous data types. Then, it applies a series of Transformer encoder layers to these projected inputs. This enables the model to learn complex relationships and interactions between the different modalities, enhancing its ability to generate contextually relevant outputs.\\\n",
    "The use of Transformer architecture here is key for capturing the sequential and relational dynamics in the data, making it a critical component for the multimodal learning capabilities of the Mirasol model.\n",
    "\n",
    "#### ContextAutoregressiveModel\n",
    "This is one of the key model in the Mirasol architecture since it integrate sequential, non-aligned context modalities such as text in order to be combined with the time-aligned modalities like video and audio. It employs an embedding layer to convert token IDs into a meaningful representation, which is then processed by a Transformer encoder to capture the sequential nature of the context. As suggested in the paper, there is a cross-attention mechanism that subsequently merges this context with the combined video-audio latent space `combined_latent`, focusing on extracting relevant features. The model utilizes average pooling post cross-attention to distill the sequence into a single representative embedding, which is then passed through a fully connected layer to produce the final output.\n",
    "\n",
    "\n",
    "#### TemporalAutoregressiveModel\n",
    "Another key model in the Mirasol architecture which aim to handle time-aligned modalities like audio and video data. It consists of an embedding layer that maps input tokens to high-dimensional vectors, a Transformer decoder that autoregressively processes the embeddings while considering the entire sequence up to the current step, and a fully connected output layer that maps the decoder's output to the vocabulary size, predicting the next token.\\\n",
    "This model is crucial for capturing the temporal dependencies and generating sequences in a manner consistent with the learned patterns from time-synchronized inputs.\n",
    "\n",
    "### Mirasol model\n",
    "\n",
    "The MirasolModel integrates all previoyus components to process and generate sequences based on multi-modal inputs (audio, video, and context).\\\n",
    "It process the inputs through its `forward` method:\n",
    "\n",
    "1. Audio Processing: The audio input is converted into a Mel spectrogram via the AudioExtractor.\n",
    "\n",
    "2. Video Processing: Concurrently, the video input is passed through the VideoExtractor to obtain video features.\n",
    "\n",
    "3. Combining Modalities: The extracted audio and video features are concatenated and fed into the CombinerModel to create a unified representation.\n",
    "\n",
    "4. Context Processing: If context input is provided, it is incorporated using the ContextAutoregressiveModel to enhance the combined representation with contextual information.\n",
    "\n",
    "5. Sequence Generation: The TemporalAutoregressiveModel uses the enriched latent representation to autoregressively predict the next token in the sequence.\n",
    "\n",
    "6. Output: The final output is a sequence generated from the model, which integrates audio, video, and context information to make predictions.\n",
    "\n",
    "The training phase involves iteratively processing batches of multimodal inputs—audio, video, and contextual text—through the model. For each batch, the model extracts features, combines them, processes context, and then predicts the target sequence. The predictions are compared to the actual targets using a __CrossEntropyLoss__ function to compute the loss, which is then minimized using the __AdamW__ optimizer. This phase refines the model's parameters to better align its predictions with the expected outputs.\n",
    "\n",
    "After the training there is the generation. The model is set to evaluation mode and a sequence is generated token by token. Starting with an initial token the model predicts subsequent tokens using the combined features of audio and video inputs, enriched by context when available. This autoregressive process continues until an end token is predicted or a maximum sequence length is reached. The outcome is a sequence that mirrors the training target patterns, representing the model's best guess based on learned multimodal relationships.\n",
    "\n",
    "\n",
    "## Execution and evaluation\n",
    "\n",
    "### Loss evaluation\n",
    "![Texte alternatif](loss-evolution-500.png \"Titre facultatif\")\\\n",
    "\n",
    "The loss evolution graph for the model during training shows a promising decline, indicating that the model is learning from the data. Starting at a higher value, the loss decreases significantly over 100 iterations, suggesting that the model's predictions are getting closer to the actual target values with each batch processed. However it was before I saw the model generation.\\\n",
    "\n",
    "### Generation (evaluation)\n",
    "```\n",
    "[384.923s] Generation complete\n",
    "Generated sequence: [0, 0, 0, 0, 0, ..., 0]\n",
    "Target: tensor([[103, 132, 250,  ...,  92, 174, 227]])\n",
    "```\n",
    "\\\n",
    "This phenomen often indicative of an issue with the learning process or data. In the case of using a randomly generated dataset, the model may not be learning meaningful patterns from the data. This is because the random data lacks the inherent structure and correlations present in real-world data, which the model needs to learn to make accurate predictions. Consequently, the model might converge to a trivial solution, such as predicting the most frequent class, which in this case appears to be zero.\n",
    "\n",
    "### About the VideoQA dataset\n",
    "In the beginning I underestimated the importance of setting a data segmentation into timechunks, which is important and mentionned in the paper.\\\n",
    "I realized how it was when I wanted to work with real datas such as the _MSRVTT_ dataset. Even if I suceeded having a pseudo-dataset from _MSRVTT_, I had to trim the video frames and audio samples in order to let my computer process the training, since I don't have GPU.\\\n",
    "It is also for this reason that I runned the training on single-batch each time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from generate_dataset import CustomVideoDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mirasol model configuration\n",
    "model_dim = 512  # Dimension of the model\n",
    "context_dim = 1024  # Assuming context dimension\n",
    "heads = 8  # Number of attention heads\n",
    "depth = 3  # Depth of the transformer\n",
    "vocab_size = 256  # Size of the vocabulary\n",
    "max_seq_length = 1024  # Maximum sequence length\n",
    "start_token_id = 0  # 0 is the start token\n",
    "end_token_id = 1  # 1 is the end token\n",
    "epochs = 1  # Number of epochs to train\n",
    "batch_size = 1  # Batch size\n",
    "video_dir = \"dataset/videos/\"  # Path to video directory\n",
    "annotations_file = \"dataset/corpus.json\"  # Path to annotations file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random dataset\n",
    "class RandomData(Dataset):\n",
    "    def __init__(self, n=1000):\n",
    "        self.n = n\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_input = torch.randn(1, 64, 1024)\n",
    "        video_input = torch.randn(1, 3, 12, 128, 128)\n",
    "        context_input = torch.randint(0, 256, (1, 1024))\n",
    "        target = torch.randint(0, 256, (1, 1024))  # Exemple de target aléatoire\n",
    "        return audio_input, video_input, context_input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video feature extractor model\n",
    "# Done with ChatGPT's help\n",
    "class VideoExtractor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VideoExtractor, self).__init__()\n",
    "        \n",
    "        # Use of pretrained model from torchvision\n",
    "        self.model = torchvision.models.video.r3d_18()\n",
    "\n",
    "        # Deleting the last layer because we don't need classification here\n",
    "        self.model = torch.nn.Sequential(*(list(self.model.children())[:-1]))\n",
    "\n",
    "    def forward(self, video_tensor):\n",
    "        # Extracting features from video\n",
    "        features = self.model(video_tensor)\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio feature extractor based on Mel Spectrogram\n",
    "# Done with ChatGPT's help\n",
    "class AudioExtractor(torch.nn.Module):\n",
    "    def __init__(self, n_mels=64, sample_rate=16000, n_fft=400, hop_length=160):\n",
    "        super(AudioExtractor, self).__init__()\n",
    "        \n",
    "        self.mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sample_rate, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels\n",
    "        )\n",
    "        self.n_mels = n_mels\n",
    "\n",
    "    def forward(self, audio_waveform):\n",
    "        # Convert waveform to Mel Spectrogram\n",
    "        mel_spec = self.mel_spectrogram(audio_waveform)\n",
    "        return mel_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiner model\n",
    "class CombinerModel(nn.Module):\n",
    "    def __init__(self, model_dim, heads, depth):\n",
    "        super(CombinerModel, self).__init__()\n",
    "\n",
    "        self.model_dim = model_dim\n",
    "        self.transformer_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim, nhead=heads, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            self.transformer_layer, num_layers=depth\n",
    "        )\n",
    "        self.projection = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.projection is None:\n",
    "            input_size = input.flatten(start_dim=1).shape[1]\n",
    "            self.projection = nn.Linear(input_size, self.model_dim).to(input.device)\n",
    "\n",
    "        input = self.projection(input.flatten(start_dim=1))\n",
    "        return self.transformer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextAutoregressiveModel(nn.Module):\n",
    "    def __init__(self, context_dim, heads, depth, vocab_size, embedding_dim):\n",
    "        super(ContextAutoregressiveModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.context_encoder = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim, nhead=heads, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.context_encoder, num_layers=depth\n",
    "        )\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=embedding_dim, num_heads=heads, batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(embedding_dim, context_dim)\n",
    "\n",
    "    def forward(self, context_input, combined_latent):\n",
    "\n",
    "        # Convert token IDs to embeddings\n",
    "        context_embedded = self.embedding(context_input)\n",
    "\n",
    "        # Unsqueeze to add batch dimension\n",
    "        combined_latent = combined_latent.unsqueeze(1)\n",
    "\n",
    "        # Encode context\n",
    "        context_encoded = self.transformer_encoder(context_embedded)\n",
    "\n",
    "        # Cross-attention between combined latent space and context\n",
    "        attn_output, _ = self.cross_attention(\n",
    "            query=context_encoded, key=combined_latent, value=combined_latent\n",
    "        )\n",
    "\n",
    "        # Average pooling over the sequence dimension after cross-attention\n",
    "        attn_output_mean = attn_output.mean(dim=1)\n",
    "\n",
    "        # Final fully connected layer\n",
    "        output = self.fc(attn_output_mean)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalAutoregressiveModel(nn.Module):\n",
    "    def __init__(self, model_dim, vocab_size, heads, depth):\n",
    "        super(TemporalAutoregressiveModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, model_dim)\n",
    "        transformer_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=model_dim, nhead=heads, batch_first=True\n",
    "        )\n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            transformer_layer, num_layers=depth\n",
    "        )\n",
    "        self.fc_out = nn.Linear(model_dim, vocab_size)\n",
    "\n",
    "    \n",
    "    def generate_square_subsequent_mask(self, sz, device):\n",
    "        mask = torch.triu(torch.ones((sz, sz), device=device), 1)\n",
    "        mask = mask.masked_fill(mask == 1, float(\"-inf\"))\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def forward(self, tgt, memory):\n",
    "        tgt_emb = self.embedding(tgt.long()).squeeze(0)\n",
    "\n",
    "        tgt_mask = self.generate_square_subsequent_mask(tgt.size(1), tgt.device)\n",
    "        memory = memory.squeeze(1)\n",
    "\n",
    "        output = self.transformer_decoder(tgt=tgt_emb, memory=memory, tgt_mask=tgt_mask)\n",
    "        output = self.fc_out(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MirasolModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        model_dim,\n",
    "        heads,\n",
    "        depth,\n",
    "        vocab_size,\n",
    "        max_seq_length,\n",
    "    ):\n",
    "        super(MirasolModel, self).__init__()\n",
    "        self.audio_extractor = AudioExtractor()\n",
    "        self.video_extractor = VideoExtractor()\n",
    "        self.combiner = CombinerModel(model_dim, heads, depth)\n",
    "        self.context_processor = ContextAutoregressiveModel(\n",
    "            model_dim, heads, depth, vocab_size, model_dim\n",
    "        )\n",
    "\n",
    "        self.decoder = TemporalAutoregressiveModel(model_dim, vocab_size, heads, depth)\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "        # AdamW is often recommended for Transformer-based models because of its ability to handle weights.\n",
    "        # more efficiently than the classic Adam optimizer. It helps prevent overfitting on the drive dataset.\n",
    "        self.optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4)\n",
    "\n",
    "        # CrossEntropyLoss is commonly used for classification tasks, including text generation, where each generated token can be treated\n",
    "        # as a class in a multi-class classification problem.\n",
    "        # This loss function calculates the probability of each token being the correct class and penalizes incorrect predictions.\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, audio_input, video_input, context_input, target):\n",
    "        encoded_audio = self.audio_extractor(audio_input).flatten(start_dim=1)\n",
    "        encoded_video = self.video_extractor(video_input).flatten(start_dim=1)\n",
    "\n",
    "        # Combine audio and video representations, making sure they have the same second dimension\n",
    "        combined_av = torch.cat((encoded_audio, encoded_video), dim=1)\n",
    "\n",
    "        # Using the combiner model to combine audio and video representations\n",
    "        combined_latent = self.combiner(combined_av)\n",
    "\n",
    "        # Context input processing with associated auto-regressive model\n",
    "        if context_input is not None:\n",
    "            combined_latent = self.context_processor(context_input, combined_latent)\n",
    "        \n",
    "        # Auto-regressive model for target generation\n",
    "        decoded_output = self.decoder(target, combined_latent)\n",
    "\n",
    "        return decoded_output\n",
    "\n",
    "    def train_model(self, epochs, train_loader):\n",
    "        self.train() \n",
    "        start_time = time.time()\n",
    "\n",
    "        loss_eval = []\n",
    "        for epoch in range(epochs):\n",
    "            for i, batch in enumerate(train_loader):\n",
    "                audio_input, video_input, context_input, target = batch\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Get rid of the batch dimension\n",
    "                audio_input = audio_input.squeeze(0)\n",
    "                video_input = video_input.squeeze(0)\n",
    "                context_input = context_input.squeeze(0)\n",
    "                target = target.squeeze(0)\n",
    "\n",
    "                # Combined model output\n",
    "                combined = self(audio_input, video_input, None, target)\n",
    "\n",
    "                # Reshape to get [batch_size * seq_length, num_classes]\n",
    "                combined = combined.view(-1, 256)\n",
    "\n",
    "                # Reshape to get [batch_size * seq_length]\n",
    "                target = target.view(-1)\n",
    "\n",
    "                loss = self.criterion(combined, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                loss_eval.append(loss.item())\n",
    "\n",
    "                # if i % 20 == 0 or i < 20:\n",
    "                #     print(\n",
    "                #         f\"[{(time.time() - start_time).__format__('.3f')}s] Epoch {epoch}, Batch {i}, Loss: {loss.item()}\"\n",
    "                #     )\n",
    "\n",
    "            print(\n",
    "                f\"[{(time.time() - start_time).__format__('.3f')}s] Epoch {epoch}, Loss: {loss.item()}\"\n",
    "            )\n",
    "        \n",
    "        return loss_eval\n",
    "\n",
    "    def generate(\n",
    "        self, audio_input, video_input, context_input, start_token_id, end_token_id\n",
    "    ):\n",
    "        self.eval()\n",
    "        start_time = time.time()\n",
    "\n",
    "        generated_sequence = [start_token_id]  # Commence avec le token de début\n",
    "\n",
    "        for _ in range(self.max_seq_length):\n",
    "            # Convert the sequence generated so far into tensor and add a batch dimension\n",
    "            target = torch.LongTensor([generated_sequence])\n",
    "\n",
    "            # Get the model output for the generated sequence\n",
    "            output = self.forward(audio_input, video_input, context_input, target)\n",
    "\n",
    "            # Select the last token in the sequence (best prediction)\n",
    "            next_token = output.argmax(dim=-1)[-1].item()\n",
    "            generated_sequence.append(next_token)\n",
    "\n",
    "            if next_token == end_token_id:\n",
    "                break\n",
    "\n",
    "        print(f\"[{(time.time() - start_time).__format__('.3f')}s] Generation complete\")\n",
    "        return generated_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model = MirasolModel(\n",
    "    model_dim=model_dim,\n",
    "    heads=heads,\n",
    "    depth=depth,\n",
    "    vocab_size=vocab_size,\n",
    "    max_seq_length=max_seq_length,\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset\n",
    "dataset = RandomData(n=500) # random dataset with n samples\n",
    "# dataset = CustomVideoDataset(video_dir, annotations_file, max_frames=12) # error during training...    \n",
    "\n",
    "# DataLoader for iterating over the dataset\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[689.235s] Epoch 0, Loss: 0.00696333684027195\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "loss_eval = model.train_model(epochs, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAHFCAYAAADcytJ5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABM7UlEQVR4nO3dd3xT5f4H8M/JbpM23ZPSIruUsqeDUQFZilwXIiB67/2BonKRq+IdgKtcHNeN84ITcIETFBQQBWTLRpBVaCl0pjPNeH5/pImE7jbNSdrP+/XKS3vyJPmepyH95Hmec44khBAgIiIi8kEKuQsgIiIiqgmDChEREfksBhUiIiLyWQwqRERE5LMYVIiIiMhnMagQERGRz2JQISIiIp/FoEJEREQ+i0GFiIiIfBaDip9YtmwZJEnCzp075S7FJ23cuBGSJGHjxo0NfmxpaSkWLFhQ7WOd/X7q1Kkm19hQFRUVmDFjBmJjY6FUKtGzZ89mfb2DBw/innvuwaBBg6DX6xvdn75q6NChSElJkbsMl6SkJNx5550Nflxt71c5ZGZmYsGCBdi7d6/HnnPBggWQJMljz9cUzlouv+l0umrbr1ixAj179oROp0NcXBxmz56N4uLiKu2Ki4sxe/ZsxMXFQafToWfPnlixYkVz745fUsldAJHcSktLsXDhQgCOP2aXGjt2LLZu3YrY2Fiv17VkyRK8/vrreOmll9CnTx8YDIZmfb2dO3di9erV6NWrF9LS0vDll1826+tR49T2fpVDZmYmFi5ciKSkJI+F6T//+c+47rrrPPJcnrJ27VoYjUbXzwpF1e/5H3zwAe644w78+c9/xn//+1/89ttvePjhh3Ho0CF89913bm0nTpyIHTt2YNGiRejUqRM+/PBDTJo0CXa7Hbfffnuz748/YVAhqkVkZCQiIyNlee0DBw4gICAAs2bN8thzlpWVISAgoNr7pkyZgmnTpgEAPvnkEwYVkk2bNm3Qpk0buctw06dPH0RERNR4v81mw9///neMHDkSb775JgBg2LBhCAoKwuTJk7FmzRqMHj0aAPDNN99g3bp1rnDibHv69Gn8/e9/x6233gqlUtn8O+UnOPXTwvz0009IS0tDUFAQAgMDMXjwYHz99ddubUpLSzF37ly0a9cOOp0OYWFh6Nu3L5YvX+5qc+LECdx2222Ii4uDVqtFdHQ00tLS6jW8u3PnTlx//fUICwuDTqdDr1698NFHH7nu//XXXyFJEt5+++0qj12zZg0kScIXX3zRoH2qztChQ6v9xnnnnXciKSkJAHDq1ClXEFm4cKFrWNc5JF/T1M///vc/9OjRw9V/N954Iw4fPlzldQwGA44fP44xY8bAYDAgISEBDz74IMxmc621S5KEt956C2VlZa6ali1bBgAoLy/HvHnz0K5dO2g0GsTHx+Pee+9FQUGB23MkJSVh3Lhx+Oyzz9CrVy/odDrXN/HqVPcNsaFWrlzpmjoyGAwYNWoU9uzZ49bG2S8HDx5EWloa9Ho9IiMjMWvWLJSWlrq1re++AsCHH36IQYMGwWAwwGAwoGfPntW+x3bs2IGrr74agYGBuOKKK7Bo0SLY7XbX/Xa7HU888QQ6d+6MgIAAhISEIDU1FS+88EKj+sRiseChhx5CTEwMAgMDcdVVV2H79u1V2l28eBH33HMPkpOTYTAYEBUVheHDh2Pz5s2uNnW9X48fP47p06ejY8eOCAwMRHx8PMaPH4/9+/e7vVZ99/HYsWO4/fbbERUVBa1Wi65du+KVV15x3b9x40b069cPADB9+nRXPQsWLKixP+rz+XP51I/z32F1t0v/jQsh8Oqrr6Jnz54ICAhAaGgobrrpJpw4caLGejxl27ZtyMrKwvTp092233zzzTAYDFi1apVr26pVq2AwGHDzzTe7tZ0+fToyMzPxyy+/NHu9/oRBpQXZtGkThg8fjsLCQrz99ttYvnw5goKCMH78eKxcudLVbs6cOViyZAnuv/9+rF27Fu+99x5uvvlm5ObmutqMGTMGu3btwuLFi7Fu3TosWbIEvXr1qvYPxKU2bNiAK6+8EgUFBXjttdfw+eefo2fPnrj11ltdf2h79OiBXr16YenSpVUev2zZMkRFRWHMmDEN2qfGio2Nxdq1awEAd999N7Zu3YqtW7fiX//6V42PSU9Px913341u3brhs88+wwsvvIB9+/Zh0KBBOHbsmFtbi8WC66+/Hmlpafj8889x11134b///S/+85//1FrX1q1bMWbMGAQEBLhqGjt2LIQQmDBhAp555hlMmTIFX3/9NebMmYN33nkHw4cPrxKAdu/ejb///e+u3/Wf/vSnRvZU3Z566ilMmjQJycnJ+Oijj/Dee++hqKgIV199NQ4dOuTW1mKxYMyYMUhLS8Pq1asxa9YsvP7667j11ltdbRqyr//+978xefJkxMXFYdmyZVi1ahWmTZuG06dPu73u+fPnMXnyZNxxxx344osvMHr0aMybNw/vv/++q83ixYuxYMECTJo0CV9//TVWrlyJu+++u873fk3+8pe/4JlnnsHUqVPx+eef409/+hMmTpyI/Px8t3Z5eXkAgPnz5+Prr7/G0qVLccUVV2Do0KGu9Sh1vV8zMzMRHh6ORYsWYe3atXjllVegUqkwYMAAHD16tEH7eOjQIfTr1w8HDhzAs88+i6+++gpjx47F/fff7wq8vXv3dv07/uc//+mq589//nON/VGfz5/LOadgL70999xzAIBu3bq52v3f//0fZs+ejWuvvRarV6/Gq6++ioMHD2Lw4MHIzs52tXOuaastUF2ue/fuUCqViI6OxtSpU3HmzBm3+w8cOAAASE1NdduuVqvRpUsX1/3Otl27doVK5T6p4XzspW0JgCC/sHTpUgFA7Nixo8Y2AwcOFFFRUaKoqMi1zWq1ipSUFNGmTRtht9uFEEKkpKSICRMm1Pg8OTk5AoB4/vnnG1xnly5dRK9evYTFYnHbPm7cOBEbGytsNpsQQogXX3xRABBHjx51tcnLyxNarVY8+OCDDd6nDRs2CABiw4YNrnZDhgwRQ4YMqVLjtGnTRGJiouvnixcvCgBi/vz5Vdo6+/3kyZNCCCHy8/NFQECAGDNmjFu7M2fOCK1WK26//Xa31wEgPvroI7e2Y8aMEZ07d67yWtXVqdfr3batXbtWABCLFy92275y5UoBQLzxxhuubYmJiUKpVLr1cX19/PHHVfqzNmfOnBEqlUrcd999btuLiopETEyMuOWWW1zbnP3ywgsvuLV98sknBQDx008/CSHqv68nTpwQSqVSTJ48udYahwwZIgCIX375xW17cnKyGDVqlOvncePGiZ49e9Zrv+ty+PBhAUD87W9/c9v+wQcfCABi2rRpNT7WarUKi8Ui0tLSxI033ujaXtv7tbrnqKioEB07dnSroT77OGrUKNGmTRtRWFjotn3WrFlCp9OJvLw8IYQQO3bsEADE0qVL66xHiLo/f4QQYv78+aK2P09HjhwR4eHhYtiwYcJsNgshhNi6dasAIJ599lm3thkZGSIgIEA89NBDrm0bN24USqVSLFy4sM563333XfHkk0+Kb775Rvzwww9i0aJFIiwsTERHR4uzZ8+62jnfv1lZWVWeY+TIkaJTp06unzt27Oj2nnPKzMwUAMRTTz1VZ12tCUdUWoiSkhL88ssvuOmmm9wWXSqVSkyZMgVnz551faPq378/1qxZg0ceeQQbN25EWVmZ23OFhYWhffv2ePrpp/Hcc89hz549bkPjNTl+/DiOHDmCyZMnAwCsVqvrNmbMGGRlZblqmDx5MrRarWuUBQCWL18Os9nsGjptyD55y9atW1FWVlblaI2EhAQMHz4c33//vdt2SZIwfvx4t22pqalVvunX1w8//AAAVV7/5ptvhl6vr/L6qamp6NSpU6NeqyG+/fZbWK1WTJ061e33rtPpMGTIkGqPUHG+T5ycCwg3bNgAoP77um7dOthsNtx777111hkTE4P+/fu7bbv899G/f3/8+uuvuOeee/Dtt9/CZDLV+bw1ce7L5ft6yy23VPk2DQCvvfYaevfuDZ1OB5VKBbVaje+//77KtGJNrFYrnnrqKSQnJ0Oj0UClUkGj0eDYsWNuz1HXPpaXl+P777/HjTfeiMDAwCr/lsvLy7Ft27aGdofrtWv7/KnL+fPncd111yE2NharVq2CRqMBAHz11VeQJAl33HGHW70xMTHo0aOH23twyJAhsFqt+Pe//13n602ZMgWPPvooRo8ejWHDhuHhhx/GmjVrcPHiRSxevLhK+5qOVrp8e21HNfnKEU++gkGlhcjPz4cQotqjU+Li4gDANbT64osv4uGHH8bq1asxbNgwhIWFYcKECa5pC0mS8P3332PUqFFYvHgxevfujcjISNx///0oKiqqsQbn0OrcuXOhVqvdbvfccw8AICcnB4AjDF1//fV49913YbPZADimffr37+8aym3IPnmL8/VqqunyegIDA6scxqjValFeXt7o11epVFUW+EqShJiYmCqv762jlZy/+379+lX53a9cudL1e3dSqVQIDw932xYTEwPgjz6u775evHgRAOq1+PLy1wQcv49L/1jOmzcPzzzzDLZt24bRo0cjPDwcaWlpjTo1gLNG5745Vbf/zz33HGbOnIkBAwbg008/xbZt27Bjxw5cd9119f5jPmfOHPzrX//ChAkT8OWXX+KXX37Bjh070KNHjwbtY25uLqxWK1566aUqv0/ntOzlv9P6quvzpzZFRUUYM2YMLBYL1qxZ43YUTnZ2NoQQiI6OrlLztm3bGl1vdfr3749OnTq5hTXn77O6z6S8vDyEhYW5ta2pHQC3tsSjflqM0NBQKBQKZGVlVbkvMzMTAFwr1vV6PRYuXIiFCxciOzvb9e1m/PjxOHLkCAAgMTHRtRDxt99+w0cffYQFCxagoqICr732WrU1OJ9/3rx5mDhxYrVtOnfu7Pr/6dOn4+OPP8a6devQtm1b7NixA0uWLGnUPlVHp9OhsLCwyvamfGA5P4xqqqm2ejwhPDwcVqsVFy9edPsDLoTA+fPnXQsbnbz1zcy535988gkSExPrbG+1WpGbm+v2x/r8+fMA/ujj+u6r876zZ88iISGhyfuiUqkwZ84czJkzBwUFBVi/fj0effRRjBo1ChkZGQgMDKz3czn35fz584iPj3dtd+7/pd5//30MHTrU7d8AgFq/HFzu/fffx9SpU/HUU0+5bc/JyUFISIjr57r2MTQ01DVyWdNIVbt27epd16Xq8/lTHYvFgj/96U/4/fffsXnz5irBNCIiApIkYfPmzdBqtVUeX922phBCuC1A7969OwBg//79SE5Odm23Wq04cuSI6+geZ9vly5fDarW6jaw5Fz370vl+fAFHVFoIvV6PAQMG4LPPPnP75mS32/H++++jTZs21U4BREdH484778SkSZNw9OjRKkddAECnTp3wz3/+E927d8fu3btrrKFz587o2LEjfv31V/Tt27faW1BQkKv9yJEjER8fj6VLl2Lp0qXQ6XRu/5gbu09OSUlJ+O2339wWXebm5mLLli1u7ZwfYPX51jpo0CAEBAS4Lb4EHH8kf/jhB6SlpdX5HE3hfP7LX//TTz9FSUlJs79+TUaNGgWVSoXff/+9xt/95T744AO3nz/88EMAf5wbpL77OnLkSCiVyip/4D0hJCQEN910E+69917k5eU1+MR/zn25fF8/+ugjWK1Wt22SJFX5Y7pv3z5s3brVbVtt79fqnuPrr7/GuXPnaqyxun0MDAzEsGHDsGfPHqSmplb7+3SGsIb8+7lcfT5/nO6++25s3LgRn332WZUFqwAwbtw4CCFw7ty5aut1BglP2LZtG44dO4aBAwe6tg0YMACxsbFu09mAI7wXFxe7fXm78cYbUVxcjE8//dSt7TvvvIO4uDgMGDDAY7W2BBxR8TM//PBDtR+WY8aMQXp6OkaMGIFhw4Zh7ty50Gg0ePXVV3HgwAEsX77c9e16wIABGDduHFJTUxEaGorDhw/jvffew6BBgxAYGIh9+/Zh1qxZuPnmm9GxY0doNBr88MMP2LdvHx555JFa63v99dcxevRojBo1CnfeeSfi4+ORl5eHw4cPY/fu3fj4449dbZVKJaZOnYrnnnsOwcHBmDhxottQLoB671N1pkyZgtdffx133HEH/vKXvyA3NxeLFy9GcHCwW7ugoCAkJibi888/R1paGsLCwhAREeE6hPlSISEh+Ne//oVHH30UU6dOxaRJk5Cbm4uFCxdCp9Nh/vz5tfZPU40YMQKjRo3Cww8/DJPJhCuvvBL79u3D/Pnz0atXL0yZMqXRz11aWopvvvkGAFxD2ps2bUJOTg70er3rHBDVSUpKwmOPPYZ//OMfOHHiBK677jqEhoYiOzsb27dvd32LdtJoNHj22WdRXFyMfv36YcuWLXjiiScwevRoXHXVVQ3a16SkJDz66KN4/PHHUVZWhkmTJsFoNOLQoUPIycmp9ZDs6owfPx4pKSno27cvIiMjcfr0aTz//PNITExEx44dXe0kSapx/Y1T165dcccdd+D555+HWq3GtddeiwMHDuCZZ56p8j4cN24cHn/8ccyfPx9DhgzB0aNH8dhjj6Fdu3Zuoaa29+u4ceOwbNkydOnSBampqdi1axeefvrpKqMP9dnHF154AVdddRWuvvpqzJw5E0lJSSgqKsLx48fx5ZdfutYQtW/fHgEBAfjggw/QtWtXGAwGxMXFuaZnL1fX5091nn76abz33nu47777oNfr3aZcgoODkZycjCuvvBJ//etfMX36dOzcuRPXXHMN9Ho9srKy8NNPP6F79+6YOXMmAMf7Oi0tDf/+97/rXKfSo0cP3HHHHejatSt0Oh22b9+Op59+GjExMXjooYdc7ZRKJRYvXowpU6bg//7v/zBp0iQcO3YMDz30EEaMGOF2ArvRo0djxIgRmDlzJkwmEzp06IDly5dj7dq1eP/993kOlcvJuJCXGsB59ElNN+dRKZs3bxbDhw8Xer1eBAQEiIEDB4ovv/zS7bkeeeQR0bdvXxEaGiq0Wq244oorxN/+9jeRk5MjhBAiOztb3HnnnaJLly5Cr9cLg8EgUlNTxX//+19htVrrrPXXX38Vt9xyi4iKihJqtVrExMSI4cOHi9dee61K299++821D+vWrav2+eqzT9Ud9SOEEO+8847o2rWr0Ol0Ijk5WaxcubLKUT9CCLF+/XrRq1cvodVq3Y7GuPyoH6e33npLpKamCo1GI4xGo7jhhhvEwYMH3dpUd9SOEHUf0VDX48vKysTDDz8sEhMThVqtFrGxsWLmzJkiPz/frV1iYqIYO3Zsna/jdPLkyRrfX5f3V01Wr14thg0bJoKDg4VWqxWJiYnipptuEuvXr6+yX/v27RNDhw4VAQEBIiwsTMycOVMUFxc3al+FcByd0a9fP6HT6YTBYBC9evVyOxJlyJAholu3blUed/n74dlnnxWDBw8WERERQqPRiLZt24q7775bnDp1ytWmqKhIABC33XZbnX1iNpvFgw8+KKKiooROpxMDBw4UW7duFYmJiW5H/ZjNZjF37lwRHx8vdDqd6N27t1i9enWD3q/5+fni7rvvFlFRUSIwMFBcddVVYvPmzVWOgKvPPgrheE/cddddIj4+XqjVahEZGSkGDx4snnjiCbd2y5cvF126dBFqtbrOI5Lq+vwRouq/EeeRYtXdLj+y73//+58YMGCA6/Oiffv2YurUqWLnzp2uNs7Pi/ocOXXbbbeJDh06CL1eL9RqtUhMTBQzZswQmZmZ1bb/8MMPXZ8NMTEx4v7773c7atGpqKhI3H///SImJkZoNBqRmpoqli9fXmc9rZEkhBDeCERERIDjKB7ncLi/+uabbzBu3Dj8+uuvHp1SIKKquEaFiKiBNmzYgNtuu40hhcgLuEaFiKiBnn76ablLIGo1OPVDREREPotTP0REROSzGFSIiIjIZzGoEBERkc/y68W0drsdmZmZCAoK4kWciIiI/IQQAkVFRYiLi3O7FEF1/DqoZGZmeuTaHkREROR9GRkZdV5Q1K+DivO6MRkZGVVOR01ERES+yWQyISEhwe36bzXx66DinO4JDg5mUCEiIvIz9Vm2wcW0RERE5LMYVIiIiMhnMagQERGRz2JQISIiIp/FoEJEREQ+i0GFiIiIfBaDChEREfksBhUiIiLyWQwqRERE5LMYVIiIiMhnMagQERGRz2JQISIiIp/FoFINIQSyTeU4lVMidylEREStGoNKNd7bdhoDnvoei9YckbsUIiKiVo1BpRodogwAgENZJpkrISIiat0YVKqRHBsMADiTV4qicovM1RAREbVeDCrVCAnUIM6oAwAcOV8kczVEREStF4NKDZLjHKMqhzI5/UNERCQXBpUadI1lUCEiIpIbg0oNnAtqT+byEGUiIiK5MKjUIClcDwA4zaBCREQkGwaVGjiDSrbJjNIKq8zVEBERtU4MKjUwBqoREqgGAJzOLZW5GiIiotaJQaUWiZz+ISIikhWDSi2SwgMBAKc4okJERCQLBpVaJIY5ggqnfoiIiOTBoFKLNqGOoHKuoEzmSoiIiFonBpVaxIcGAADO5XNEhYiISA4MKrVo4wwqBWUQQshcDRERUevDoFKLWGMAJAkot9iRW1IhdzlEREStDoNKLTQqBaKDHFdRPpvPdSpERETexqBSB9f0D4MKERGR1zGo1KFt5SHK+84VyFsIERFRK8SgUocRydEAgFW7z8Fqs8tcDRERUevCoFKHtK7RCNdrcKHIjJ9/z5W7HCIiolaFQaUOGpUCA68IBwAcyy6SuRoiIqLWhUGlHpwnfsssKJe5EiIiotaFQaUe4kOcJ37jGWqJiIi8iUGlHuJCOKJCREQkBwaVeoh3BRWeS4WIiMibGFTqwRlUcksqUFZhk7kaIiKi1oNBpR6CA1QwaFUAgMxCjqoQERF5C4NKPUiS5DqV/smLJTJXQ0RE1HowqNRTtzgjAGDf2QJ5CyEiImpFGFTqqWfbEADAnowCWesgIiJqTRhU6qlXQggA4NeMAtjtQt5iiIiIWgkGlXrqHBMErUoBU7kVZ/J44jciIiJvYFCpJ7VSgbZhgQCAjHwGFSIiIm9gUGkA55E/Z/N5iDIREZE3yBpUFixYAEmS3G4xMTFyllQr58UJzzGoEBEReYVK7gK6deuG9evXu35WKpUyVlO7NqGOqZ+znPohIiLyCtmDikql8ulRlEv9cRVljqgQERF5g+xrVI4dO4a4uDi0a9cOt912G06cOFFjW7PZDJPJ5Hbzpjac+iEiIvIqWYPKgAED8O677+Lbb7/Fm2++ifPnz2Pw4MHIzc2ttn16ejqMRqPrlpCQ4NV6nWtUzpvKYbHZvfraRERErZEkhPCZs5eVlJSgffv2eOihhzBnzpwq95vNZpjNZtfPJpMJCQkJKCwsRHBwcLPXJ4RAp3+ugcUmsOWR4YirnAoiIiKi+jOZTDAajfX6+y37GpVL6fV6dO/eHceOHav2fq1WC61W6+Wq/iBJEiINWmQWluNikZlBhYiIqJnJvkblUmazGYcPH0ZsbKzcpdQoMsgRlC4UmetoSURERE0la1CZO3cuNm3ahJMnT+KXX37BTTfdBJPJhGnTpslZVq2cQeUigwoREVGzk3Xq5+zZs5g0aRJycnIQGRmJgQMHYtu2bUhMTJSzrFpFBukAABeKymWuhIiIqOWTNaisWLFCzpdvFI6oEBEReY9PrVHxBwwqRERE3sOg0kBRXExLRETkNQwqDcQRFSIiIu9hUGmgqEuCig+dK4+IiKhFYlBpoAiDI6hU2OwwlVllroaIiKhlY1BpIJ1aiWCd42Cpi8U8RJmIiKg5Mag0QlRw5blUTFynQkRE1JwYVBohsnL652IxgwoREVFzYlBphKjgykOUOaJCRETUrBhUGoEjKkRERN7BoNIIPJcKERGRdzCoNIJr6ocXJiQiImpWDCqNEGlwHPXDERUiIqLmxaDSCJz6ISIi8g4GlUZwnkY/v9SCCqtd5mqIiIhaLgaVRggJVEOtlAAAOTzyh4iIqNkwqDSCJEmuQ5QvcPqHiIio2TCoNBLXqRARETU/BpVGYlAhIiJqfgwqjRQZVHlhQp5LhYiIqNkwqDQSR1SIiIiaH4NKIzmDChfTEhERNR8GlUaKdgYVE6d+iIiImguDSiPFhwYAADLyy2SuhIiIqOViUGmkhLBAAEBeSQVKzFaZqyEiImqZGFQaKVinRkigGgCQkV8qczVEREQtE4NKEySEOkZVzuQyqBARETUHBpUmSAjjOhUiIqLmxKDSBM51Khl5HFEhIiJqDgwqTeCc+jnLERUiIqJmwaDSBNHBPI0+ERFRc2JQaYLoYOdJ33h2WiIioubAoNIEUZUXJrxYbIbNLmSuhoiIqOVhUGmCCIMGkgTY7AJ5JRVyl0NERNTiMKg0gUqpQITBMf2TzWv+EBEReRyDShNFua6izKBCRETkaQwqTeQ68ocLaomIiDyOQaWJnCMq2QwqREREHseg0kSc+iEiImo+DCpNFFEZVHKLedQPERGRpzGoNFG4vjKolHDqh4iIyNMYVJoo3KABAOTyPCpEREQex6DSRBHOoMKpHyIiIo9jUGki59RPYZkFFVa7zNUQERG1LAwqTWQMUEOpkAAA+aUcVSEiIvIkBpUmUigkhOkd0z85xVxQS0RE5EkMKh4Qruc6FSIioubAoOIBzgsT8hBlIiIiz/KZoJKeng5JkjB79my5S2kw5yHKvN4PERGRZ/lEUNmxYwfeeOMNpKamyl1Ko3SJCQYAfHcoW+ZKiIiIWhbZg0pxcTEmT56MN998E6GhoXKX0yh/6hMPlULCrtP5OHLeJHc5RERELYbsQeXee+/F2LFjce2119bZ1mw2w2Qyud18QVSQDoM7RAAAdpzKl7kaIiKilkMl54uvWLECu3fvxo4dO+rVPj09HQsXLmzmqhonsnJBbXG5VeZKiIiIWg7ZRlQyMjLwwAMP4P3334dOp6vXY+bNm4fCwkLXLSMjo5mrrL8gnSPzFZVbZK6EiIio5ZBtRGXXrl24cOEC+vTp49pms9nw448/4uWXX4bZbIZSqXR7jFarhVar9Xap9eIMKsVmjqgQERF5imxBJS0tDfv373fbNn36dHTp0gUPP/xwlZDi6/4YUWFQISIi8hTZgkpQUBBSUlLctun1eoSHh1fZ7g+CdGoAnPohIiLyJNmP+mkpDFqOqBAREXmarEf9XG7jxo1yl9BonPohIiLyPI6oeAgX0xIREXkeg4qHcI0KERGR5zGoeMila1SEEDJXQ0RE1DIwqHiIc+rHahcwW+0yV0NERNQyMKh4iF6jgiQ5/t/E6R8iIiKPYFDxEIVCgkFTuaCWR/4QERF5BIOKB/EQZSIiIs9iUPEgA4MKERGRRzGoeFCMMQAAcCKnWOZKiIiIWgYGFQ/q3TYEALD7dL68hRAREbUQDCoe1LttKABg95kCeQshIiJqIRhUPKhn2xBIEnAmrxQXi8xyl0NEROT3GFQ8KFinRkJoIADgVG6JzNUQERH5PwYVDws3aAAAeSUVMldCRETk/xhUPCwskEGFiIjIUxhUPCxMz6BCRETkKQwqHhbGqR8iIiKPYVDxME79EBEReQ6Dioc5p35yGVSIiIiajEHFw5xH/eQzqBARETUZg4qHhXLqh4iIyGMYVDwsXK8FAOSW8My0RERETcWg4mGhejUAoNxiR1mFTeZqiIiI/BuDiocZtCpoVY5u5fV+iIiImoZBxcMkSUJcSAAAILOwTOZqiIiI/BuDSjOINeoAAJkFDCpERERNwaDSDJwjKlmF5TJXQkRE5N8YVJpBXOWIyjmOqBARETUJg0ozcI2oMKgQERE1CYNKM4h1LqYt4NQPERFRUzCoNIP4kMrFtDzqh4iIqEkYVJpBrNExolJUbkVRuUXmaoiIiPwXg0oz0GtVMAY4zlDLI3+IiIgaj0GlmcTyyB8iIqImY1BpJvGuBbUMKkRERI3FoNJMYisX1GbxyB8iIqJGY1BpJnEcUSEiImoyBpVmEmfkhQmJiIiaikGlmcTxpG9ERERNxqDSTCIMGgBAXkmFzJUQERH5LwaVZhJceR6VYrMVNruQuRoiIiL/xKDSTIJ0Ktf/F5dbZayEiIjIfzGoNBOtSgmtytG9Jp5Gn4iIqFEYVJpRkM4x/cOgQkRE1DgMKs0oOMAx/VPEqR8iIqJGYVBpRsHOEZUyjqgQERE1BoNKM3IuqOWIChERUeMwqDQj5yHKXKNCRETUOAwqzSi4ckTFVMYRFSIiosaQNagsWbIEqampCA4ORnBwMAYNGoQ1a9bIWZJHOdeoFHFEhYiIqFFkDSpt2rTBokWLsHPnTuzcuRPDhw/HDTfcgIMHD8pZlsc416hw6oeIiKhxGhVUMjIycPbsWdfP27dvx+zZs/HGG2806HnGjx+PMWPGoFOnTujUqROefPJJGAwGbNu2rTFl+RznGhUupiUiImqcRgWV22+/HRs2bAAAnD9/HiNGjMD27dvx6KOP4rHHHmtUITabDStWrEBJSQkGDRpUbRuz2QyTyeR282UcUSEiImqaRgWVAwcOoH///gCAjz76CCkpKdiyZQs+/PBDLFu2rEHPtX//fhgMBmi1WsyYMQOrVq1CcnJytW3T09NhNBpdt4SEhMaU7zXONSp5JQwqREREjdGooGKxWKDVagEA69evx/XXXw8A6NKlC7Kyshr0XJ07d8bevXuxbds2zJw5E9OmTcOhQ4eqbTtv3jwUFha6bhkZGY0p32u6xAYDAI6eNyGn2CxzNURERP6nUUGlW7dueO2117B582asW7cO1113HQAgMzMT4eHhDXoujUaDDh06oG/fvkhPT0ePHj3wwgsvVNtWq9W6jhBy3nxZfEgAUuKDYRfAD4cvyF0OERGR32lUUPnPf/6D119/HUOHDsWkSZPQo0cPAMAXX3zhmhJqLCEEzOaWM/owMjkGALDhKIMKERFRQ6ka86ChQ4ciJycHJpMJoaGhru1//etfERgYWO/nefTRRzF69GgkJCSgqKgIK1aswMaNG7F27drGlOWTOkUHAQCyTeUyV0JEROR/GhVUysrKIIRwhZTTp09j1apV6Nq1K0aNGlXv58nOzsaUKVOQlZUFo9GI1NRUrF27FiNGjGhMWT4pJNCxoLaAFyYkIiJqsEYFlRtuuAETJ07EjBkzUFBQgAEDBkCtViMnJwfPPfccZs6cWa/nefvttxvz8n7FGVQKSxlUiIiIGqpRa1R2796Nq6++GgDwySefIDo6GqdPn8a7776LF1980aMF+ruQAA0Ax4iKEELmaoiIiPxLo4JKaWkpgoIcay++++47TJw4EQqFAgMHDsTp06c9WqC/c46o2OwCxWaeoZaIiKghGhVUOnTogNWrVyMjIwPffvstRo4cCQC4cOGCzx8y7G06tRJalaObCzj9Q0RE1CCNCir//ve/MXfuXCQlJaF///6uU95/99136NWrl0cLbAlc61S4oJaIiKhBGrWY9qabbsJVV12FrKws1zlUACAtLQ033nijx4prKUICNMg2mTmiQkRE1ECNCioAEBMTg5iYGJw9exaSJCE+Pr7JJ3trqYyuQ5QrZK6EiIjIvzRq6sdut+Oxxx6D0WhEYmIi2rZti5CQEDz++OOw2+2ertHvhQRUBhWOqBARETVIo0ZU/vGPf+Dtt9/GokWLcOWVV0IIgZ9//hkLFixAeXk5nnzySU/X6de4RoWIiKhxGhVU3nnnHbz11luuqyYDQI8ePRAfH4977rmHQeUyIYGV51Ip5dQPERFRQzRq6icvLw9dunSpsr1Lly7Iy8trclEtTWhlUMk2tZyLLRIREXlDo4JKjx498PLLL1fZ/vLLLyM1NbXJRbU0XWIdJ8fbf65Q5kqIiIj8S6OmfhYvXoyxY8di/fr1GDRoECRJwpYtW5CRkYFvvvnG0zX6vZ5tQgAAJ3NKUFBa4ZoKIiIioto1akRlyJAh+O2333DjjTeioKAAeXl5mDhxIg4ePIilS5d6uka/F6rXoF2EHgCwN6NA3mKIiIj8iCQ8eKW8X3/9Fb1794bNZvPUU9bKZDLBaDSisLDQ50/d/7eVe7FqzznMGdEJ96d1lLscIiIi2TTk73ejRlSo4dpHOkZUMvJKZa6EiIjIfzCoeElcSAAAILOwTOZKiIiI/AeDipfEGh1BJaugXOZKiIiI/EeDjvqZOHFirfcXFBQ0pZYWLb5yROVcQRmEEJAkSeaKiIiIfF+DgorRaKzz/qlTpzapoJYq2qgFAJitduSVVCDcoJW5IiIiIt/XoKDCQ48bT6tSIsKgRU6xGVmF5QwqRERE9cA1Kl4UH6ID4Jj+ISIioroxqHjRHwtqGVSIiIjqg0HFiyKDHNM9OcW8ijIREVF9MKh40R9BhVdRJiIiqg8GFS+KqFxAe7GIQYWIiKg+GFS8KMLguGoyR1SIiIjqh0HFiyK4RoWIiKhBGFS8KNI59VNshgcvWk1ERNRiMah4kXONSoXVjiKzVeZqiIiIfB+DihcFaJQwaB0nA87hgloiIqI6Mah42R8LarlOhYiIqC4MKl4WFeQ4jX5WIc9OS0REVBcGFS/rGG0AABw5XyRzJURERL6PQcXLkuOCAQCHMk0yV0JEROT7GFS8LDm2MqhkMagQERHVhUHFyzrHBEGSHKfR56n0iYiIaseg4mWBGhUSwwIBAMcvFMtcDRERkW9jUJFBVLDjyJ/cEo6oEBER1YZBRQbOc6nk8lwqREREtWJQkUG43nEq/VxeRZmIiKhWDCoyCHeenbaEIypERES1YVCRQXjlxQl5vR8iIqLaMajIIEJfuUaFIypERES1YlCRQUQQ16gQERHVB4OKDML1POqHiIioPhhUZOBco1JktqLcYpO5GiIiIt/FoCKDYJ0KGqWj67NN5TJXQ0RE5LsYVGQgSRK6xTsuTvjz8VyZqyEiIvJdsgaV9PR09OvXD0FBQYiKisKECRNw9OhROUvymrQuUQCAH45ky1wJERGR75I1qGzatAn33nsvtm3bhnXr1sFqtWLkyJEoKSmRsyyvSOsaDQD46XgOLDa7zNUQERH5JpWcL7527Vq3n5cuXYqoqCjs2rUL11xzjUxVeUfn6CCoFBLKLXbkFJsRawyQuyQiIiKfI2tQuVxhYSEAICwsrNr7zWYzzOY/zj1iMpm8UldzUCgkhOk1uFBkRm5xBYMKERFRNXxmMa0QAnPmzMFVV12FlJSUatukp6fDaDS6bgkJCV6u0rMiKg9TvsgTvxEREVXLZ4LKrFmzsG/fPixfvrzGNvPmzUNhYaHrlpGR4cUKPc95cUKe+I2IiKh6PjH1c9999+GLL77Ajz/+iDZt2tTYTqvVQqvVerGy5hXpvDghR1SIiIiqJWtQEULgvvvuw6pVq7Bx40a0a9dOznK8zjmiwqsoExERVU/WoHLvvffiww8/xOeff46goCCcP38eAGA0GhEQ0PIXlzrXqPAqykRERNWTdY3KkiVLUFhYiKFDhyI2NtZ1W7lypZxleU0Ep36IiIhqJfvUT2vmnPq5yKkfIiKiavnMUT+t0R8jKpz6ISIiqg6DioziQxzrcHKKzSitsMpcDRERke9hUJFRqF6DML1j+ufExZZ/fSMiIqKGYlCRWYdIAwDg+IVimSshIiLyPQwqMmsfpQfAoEJERFQdBhWZta8cUfn9IoMKERHR5RhUZNYhilM/RERENWFQkZlzROVUbgmsNrvM1RAREfkWBhWZxYcEIECthMUmcCavVO5yiIiIfAqDiswUCglXRHJBLRERUXUYVHyAc/rnOBfUEhERuWFQ8QHOBbW/X+BJ34iIiC7FoOIDeIgyERFR9RhUfEBSRCAA4HQuR1SIiIguxaDiA5LCHYtp80stKCy1yFwNERGR72BQ8QF6rQqRQVoAwOk8jqoQERE5Maj4iKRwx/TPqVyeS4WIiMiJQcVHOKd/TuVwRIWIiMiJQcVHJEU4gsoxnvSNiIjIhUHFR/RJDAUAbD52kdf8ISIiqsSg4iP6JoYiJFCNglILdp7Ol7scIiIin8Cg4iNUSgWGd4kCAGz67aLM1RAREfkGBhUfkhwbDADI4FWUiYiIADCo+JQYow4AkG0ql7kSIiIi38Cg4kNiK4NKViGDChEREcCg4lNijAEAHCMqdruQuRoiIiL5Maj4kKggLSQJsNgEcksq5C6HiIhIdgwqPkStVCDC4LjmD9epEBERMaj4HK5TISIi+gODio+JDnYElfOFZTJXQkREJD8GFR8TH+JYUHu2gEGFiIiIQcXHJIQFAuBJ34iIiAAGFZ+TWBlUzjCoEBERMaj4mrbhlUEll0GFiIiIQcXHJIQ6goqp3IrCUovM1RAREcmLQcXHBGiUiAxynEuF0z9ERNTaMaj4oLaV61RO5pbIXAkREZG8GFR8UJeYIADArxkF8hZCREQkMwYVH9QvKQwAsPNUnsyVEBERyYtBxQf1SQwFABzMNKG0wipzNURERPJhUPFBbUIDEBOsg9UusP9sodzlEBERyYZBxQdJkoQusY51Kr9f5IJaIiJqvRhUfFS7CD0A4GROscyVEBERyYdBxUdd4QoqHFEhIqLWi0HFR7WLMAAATjCoEBFRK8ag4qPaRTpGVDLySmG12WWuhoiISB4MKj4qNlgHrUoBi03gFC9QSERErRSDio9SKCT0TXKcT2XdoWyZqyEiIpIHg4oPG9s9DgDw1b5MmSshIiKSh6xB5ccff8T48eMRFxcHSZKwevVqOcvxOdelxEAhOc5Qm20ql7scIiIir5M1qJSUlKBHjx54+eWX5SzDZ4XpNegQ5Tj658A5nqGWiIhaH5WcLz569GiMHj1azhJ8XkqcEb9lF+PAORPSukbLXQ4REZFX+dUaFbPZDJPJ5HZr6brFGwEABzI5okJERK2PXwWV9PR0GI1G1y0hIUHukppdSlwwAE79EBFR6+RXQWXevHkoLCx03TIyMuQuqdklVwaVrMJyFJZZZK6GiIjIu/wqqGi1WgQHB7vdWrognRqxRh0A4PgFXqCQiIhaF78KKq2V88if4xeKZK6EiIjIu2Q96qe4uBjHjx93/Xzy5Ens3bsXYWFhaNu2rYyV+ZYOUQZsPpaDY9kcUSEiotZF1qCyc+dODBs2zPXznDlzAADTpk3DsmXLZKrK93SMCgIAHL/IoEJERK2LrEFl6NChEELIWYJf6BjtmPo5nGWCEAKSJMlcERERkXdwjYofSIkzQqNUINtkxsmcErnLISIi8hoGFT8QoFGiT6LjSso/H8+RuRoiIiLvYVDxE1d2CAcA/Hw8V+ZKiIiIvIdBxU9c2SECALDl9xzY7FzXQ0RErQODip/oHm9EkE4FU7kVB3ndHyIiaiUYVPyESqnAwCsc0z8/cZ0KERG1EgwqfuTqjo7pn+8OZstcCRERkXcwqPiR0SmxUCkk7M0owJHzJrnLISIianYMKn4kMkiLEcnRAIBPdp6VuRoiIqLmx6DiZ8b3iAMAbPrtosyVEBERNT8GFT8zuH04FBJw7EIxsgrL5C6HiIioWTGo+JmQQA26twkBAPzIURUiImrhGFT80LVdogAAH3OdChERtXAMKn7o1n4JUCkk7DydjwPnePI3IiJquRhU/FBUsA7XdnUc/cNFtURE1JIxqPipnm1DAACHsng+FSIiarkYVPxU19hgAMBhBhUiImrBGFT8VHJlUDmZU4LSCqvM1RARETUPBhU/FRmkRYRBCyGADUe4ToWIiFomBhU/NrxLJABg9so9OHGxWOZqiIiIPI9BxY89dkMK+rcLg8UmsHJnhtzlEBEReRyDih/TqZW4+6p2AIBPd51DucUmc0VERESexaDi54Z3iUJ0sBY5xWY8/e1RucshIiLyKAYVP6dWKrBoYioAYNmWUygorZC5IiIiIs9hUGkBhnWJQscoA2x2gS2/58pdDhERkccwqLQQV3WMAABsPpYjcyVERESew6DSQlxdGVTWHTqPC0XlMldDRETkGQwqLcTg9hFoF6FHTnEF/v7xPrnLISIi8ggGlRZCp1bizal9AAA/HrvIURUiImoRGFRakA5RQeiREAIhgBte/hnnCsrkLomIiKhJGFRamDEpMQCArMJy3PfhbgghZK6IiIio8RhUWpjJAxMxLjUWALD7TAFe//EEwwoREfktBpUWxqBV4eXbe2POiE4AgEVrjuDjXWdlroqIiKhxGFRaqFnDOuCv11wBAHh780mOqhARkV9iUGmhFAoJ9wxtD61KgaPZRRiY/j1O5pTIXRYREVGDMKi0YCGBGtxVeXXlbJMZw57ZiElvbIPFZpe5MiIiovphUGnhHr6uCzbMHYpYow4AsPVELt7afBI2O6eCiIjI9zGotALtIvRY+8A1uL5HHADgP2uPYNr/tstcFRERUd0YVFoJY6AaT9yYgsTwQADAT8dzsOt0nsxVERER1U4Sfnw4iMlkgtFoRGFhIYKDg+Uuxy8IIfD3T/bhk11noZCAW/slIFCjwk192kCnVqJdhF7uEomIqIVryN9vBpVW6FROCW55fSsuFJndtksS8OrtvTG6e6xMlRERUWvQkL/fnPpphZIi9Nj88DC8fHsvjOkeA71GCQAQAnj40304mFmI/JIKmaskIiLiiAoBKLfYcOR8Ef65ej8OnDMBAALUSvxrXDJuH9BW5uqIiKil4dQPNcruM/mY+OoWt20TesYht6QCN/SMx5UdwhFrDADgWOsiSZIcZRIRkZ9jUKFGW7XnLPJKLDiUacKnu6teI+jGXvHIyCvFkfNFuKpDBP4xtisSwgJlqJSIiPwVgwo1WbnFhtc2/Y5jF4rx+4ViHDlfVG07nVqBkckxCA1Uo3diKMoqbMjIL8WMIe0RpFN7uWoiIvIHDCrkcTa7wOJvj+CLvZno3TYUN/SMw/9+PoltJ6o/F0uvtiEIUCux72whIgwa9GobitBADc7ml+LartEYeEU4EsICUFphg00IBKiVUCu5tpuIqDVgUCGvEEJg49GLOHzehItFZuw4lYeTF0tQUmGr1+PD9BqYyiywVp7Ov01oAK7uGAGdWglTmRUhgWooFRI6RQch3KBBWKAGpRU2dIo2oNxqR2igGoEaVXPuIhERNQO/Ciqvvvoqnn76aWRlZaFbt254/vnncfXVV9frsQwqvmn9oWxs/O0CUuKM6BwThN8vlmDX6Xys2nMW5RZ7lYDSWAoJSG0TAptdQJKACIMWNrtAsdkKpSQhTK9BRJAGMcE6nM4thancgi4xwYgI0qKswoq9GQVoExqItmGBiArSIi4kAAWlFpRWWNEuQo8Kmx1BWjUMOhX0WiW0KiXMVhsumMyIMeqQWVAGjUqBWGMAKqx2SBI4KkREVA9+E1RWrlyJKVOm4NVXX8WVV16J119/HW+99RYOHTqEtm3rPiyWQcW/2OwCSoXjSKESsxUnLpYgOEBV+bMNW37PganMArPNDoNGhYIyC07nluBkTgmyTWbYhUCEQYszeaWQJMd5X7xJo1RAQMBic3/hxPBAZBaUwWJzTGElhAUgOliH0gobyi02FJVbERygQrsIA5zHSQXpVFApJGTkl6HYbEVooBohARp0jglCudWGwlILVEoJpRU2JIXroVBIqLDaEaRTwWKzo8Jqh9UmEBHkGGVSKxWosNqRV1KBWKMOeq0KARoljAFqlJitqLDaERKogdliQ4xRB7sACssqoFQooFI4Qp3FZkeZxYZIgxZWu0CF1Y780gqolQoE6VRQKiQYtCroNSooFBKEEBACrv93/n55NBgR1cVvgsqAAQPQu3dvLFmyxLWta9eumDBhAtLT0+t8PINK6yGEgF0ASoWEgtIK6LUq/H6xGFt/z0V8SABsdoHCMguUCgkBGiUkSMgtMeN8YTnOFZQhMVwPrUqBs/mlOJtfBrVSga6xQTiVUwqz1Y4LReXIKixHgFqJcosNBaUWGAMdf+RLa5jKUkhAa70ItValQIXNDsAR4CpsdggBqJUSjAEaqBQSBByd4/yEcXaV82dJAoJ1KtjsjpZKhYTyChsMOhUqrHZoVArklVTAZhdQKRVQKySolAqolBI0SgWUCgklZisCNSqEGxyjdCUVNgTrHOE3SKeGxWaHWqmARqWAUpJQZLZAp1JCp1ECArALUXkDJAAqpQSFJEGpqLxV/n+FzY7fsosQGqhBQlgghHAsOA/UKFFhtcMugOAAFZSSo63VLhzvWTugVklQKxWw2OwotzimLDUqBax2AZtNwCYENEoFtGolVJWB1Gy1QaNSIEinRn5pBSRICFAroVEpYLPbYbEJWO12aFVKlFlssNsFtGoltCqF6/dhswtoVI4gejm7cATu4AA19BolbHZH0LQJAQkSFJIjgDr6wvE7s9jsrvd7idkKrUqBQI0KReUWhFROy+rUCujUShSXW1Fhs0OtlCBVxvPL3w8AEKhVQaOUYLMDVrvj/aSr3E+rTcBa2ZcAXLVIkiMYm612BGpU0KgUUFR+cRFwfFa4/iv+2C5Vvscc++V4PsfN8ZzOfO3srT/ytuT28x/3SzW0h2ufL8/sfzzHZc9Z03a3x9Vdh4Djd+teuXsb53sel7W69Hkv/bIhhIBBq0JUsA6e1JC/37JN8FdUVGDXrl145JFH3LaPHDkSW7ZsqfYxZrMZZvMfp303mUzNWiP5DkmSoKz8txMSqAEAdIkJRpeY5gmodruAovID3mYXKKmworjcCptdIMaoc4yS6FTIKa7AiYvFiDbqEBaocY0CXSwyw6BVQaVUIDRQjfxSC37NKECAxvHHpNhshdlqR5vQAARqHB/sGfllyCwog07tGAmx2uxQKRXIyCsF4JhWKqmwQlP5h1chSbhQVA6DVg2b3Q5JkhBp0OJQlglmqw1Wm4DFbode4xgNySupQIBGiayCcggIRAfrHG1sduSWVLiet7DMAkXlNJZB6wgN5so/fLbKPxpmq93VV5f+v8UmkFPsfmmG2lwsqqZtYWN+Y0TUXK7vEYcXJ/WS7fVlCyo5OTmw2WyIjo522x4dHY3z589X+5j09HQsXLjQG+VRK6e45FuoUiEhWKdG8CWHW4fpHWEpxqhDjPGPbxqhek2NF3YckRxd7XZvu3TK5tJtzm9RVpvdbQrHeZ/zW2yx2YqyCht0aselF5zf/jVKBcosNuSXWFzf2Gr7BmmzC5jKrFArJQgAFqsdeq0KReWObWarYz2TRuUYjbBWjiJYbMIVwgLVSpRabMgtroAxQI0AtRJF5Y71T2UWG7QqBSw2xzSW1e6YOjNb7Ci32Fzfop3frAXEHyMLl4ww2GyOEZ0YoxZ5JRYUlVsgQYJOrUBJ5SiCBAmmcotjZEOlgFLh+JYPAFa7IwwqFRJ0aiUKyyyw2OxQKSRXO8coit01SqJROabyTGUWBAc4FpWXWWyosDoep1JKUCkUMFtt0KocIzFmq2O/LDbHczinC232P4KkkyRJUCkcNZdW2FyjR873hN3u+NZtE47fP+AIrorKX2CgxrFeq9hshUGrgqnMCr1WBbPVMd0ZoFEhQO0YFXF/Xdf/ARAoqgz/isrXd76fKmx2qBQKqJWSa7rYLhx1OUZ9HCMvZRYbzBY77JXvUanyNRSVv1up8kVdow3O/bI7/g3YKkcXXKN+lf9z+ehfldHBy0ZSL52YqPOxl92PGu//o5aa6sMljxFCOH4/0h8jKdW1kyTHZ5qEamoVwv0xlU8UUPlvXS6yHzJx+Xx2bWc8nTdvHubMmeP62WQyISEhoVnrI2ppLh3mvnSbk+qyBcGuYWPJ8YdWV8uHVgjgOnsxEZEnyBZUIiIioFQqq4yeXLhwocooi5NWq4VWq/VGeUREROQDZDuWUqPRoE+fPli3bp3b9nXr1mHw4MEyVUVERES+RNapnzlz5mDKlCno27cvBg0ahDfeeANnzpzBjBkz5CyLiIiIfISsQeXWW29Fbm4uHnvsMWRlZSElJQXffPMNEhMT5SyLiIiIfITsZ6ZtCp5HhYiIyP805O83z/dNREREPotBhYiIiHwWgwoRERH5LAYVIiIi8lkMKkREROSzGFSIiIjIZzGoEBERkc9iUCEiIiKfxaBCREREPkvWU+g3lfOkuiaTSeZKiIiIqL6cf7frc3J8vw4qRUVFAICEhASZKyEiIqKGKioqgtForLWNX1/rx263IzMzE0FBQZAkyaPPbTKZkJCQgIyMDF5HqBmxn72D/ew97GvvYD97T3P0tRACRUVFiIuLg0JR+yoUvx5RUSgUaNOmTbO+RnBwMP8ReAH72TvYz97DvvYO9rP3eLqv6xpJceJiWiIiIvJZDCpERETksxhUaqDVajF//nxotVq5S2nR2M/ewX72Hva1d7CfvUfuvvbrxbRERETUsnFEhYiIiHwWgwoRERH5LAYVIiIi8lkMKkREROSzGFSq8eqrr6Jdu3bQ6XTo06cPNm/eLHdJfuXHH3/E+PHjERcXB0mSsHr1arf7hRBYsGAB4uLiEBAQgKFDh+LgwYNubcxmM+677z5ERERAr9fj+uuvx9mzZ724F74vPT0d/fr1Q1BQEKKiojBhwgQcPXrUrQ372jOWLFmC1NRU1wmvBg0ahDVr1rjuZz83j/T0dEiShNmzZ7u2sa+bbsGCBZAkye0WExPjut/n+liQmxUrVgi1Wi3efPNNcejQIfHAAw8IvV4vTp8+LXdpfuObb74R//jHP8Snn34qAIhVq1a53b9o0SIRFBQkPv30U7F//35x6623itjYWGEymVxtZsyYIeLj48W6devE7t27xbBhw0SPHj2E1Wr18t74rlGjRomlS5eKAwcOiL1794qxY8eKtm3biuLiYlcb9rVnfPHFF+Lrr78WR48eFUePHhWPPvqoUKvV4sCBA0II9nNz2L59u0hKShKpqanigQcecG1nXzfd/PnzRbdu3URWVpbrduHCBdf9vtbHDCqX6d+/v5gxY4bbti5duohHHnlEpor82+VBxW63i5iYGLFo0SLXtvLycmE0GsVrr70mhBCioKBAqNVqsWLFClebc+fOCYVCIdauXeu12v3NhQsXBACxadMmIQT7urmFhoaKt956i/3cDIqKikTHjh3FunXrxJAhQ1xBhX3tGfPnzxc9evSo9j5f7GNO/VyioqICu3btwsiRI922jxw5Elu2bJGpqpbl5MmTOH/+vFsfa7VaDBkyxNXHu3btgsVicWsTFxeHlJQU/h5qUVhYCAAICwsDwL5uLjabDStWrEBJSQkGDRrEfm4G9957L8aOHYtrr73WbTv72nOOHTuGuLg4tGvXDrfddhtOnDgBwDf72K8vSuhpOTk5sNlsiI6OdtseHR2N8+fPy1RVy+Lsx+r6+PTp0642Go0GoaGhVdrw91A9IQTmzJmDq666CikpKQDY1562f/9+DBo0COXl5TAYDFi1ahWSk5NdH8zsZ89YsWIFdu/ejR07dlS5j+9pzxgwYADeffdddOrUCdnZ2XjiiScwePBgHDx40Cf7mEGlGpIkuf0shKiyjZqmMX3M30PNZs2ahX379uGnn36qch/72jM6d+6MvXv3oqCgAJ9++immTZuGTZs2ue5nPzddRkYGHnjgAXz33XfQ6XQ1tmNfN83o0aNd/9+9e3cMGjQI7du3xzvvvIOBAwcC8K0+5tTPJSIiIqBUKqskwgsXLlRJl9Q4zpXltfVxTEwMKioqkJ+fX2Mb+sN9992HL774Ahs2bECbNm1c29nXnqXRaNChQwf07dsX6enp6NGjB1544QX2swft2rULFy5cQJ8+faBSqaBSqbBp0ya8+OKLUKlUrr5iX3uWXq9H9+7dcezYMZ98PzOoXEKj0aBPnz5Yt26d2/Z169Zh8ODBMlXVsrRr1w4xMTFufVxRUYFNmza5+rhPnz5Qq9VubbKysnDgwAH+Hi4hhMCsWbPw2Wef4YcffkC7du3c7mdfNy8hBMxmM/vZg9LS0rB//37s3bvXdevbty8mT56MvXv34oorrmBfNwOz2YzDhw8jNjbWN9/PHl+e6+echye//fbb4tChQ2L27NlCr9eLU6dOyV2a3ygqKhJ79uwRe/bsEQDEc889J/bs2eM6xHvRokXCaDSKzz77TOzfv19MmjSp2kPf2rRpI9avXy92794thg8fzsMLLzNz5kxhNBrFxo0b3Q4zLC0tdbVhX3vGvHnzxI8//ihOnjwp9u3bJx599FGhUCjEd999J4RgPzenS4/6EYJ97QkPPvig2Lhxozhx4oTYtm2bGDdunAgKCnL9nfO1PmZQqcYrr7wiEhMThUajEb1793Yd7kn1s2HDBgGgym3atGlCCMfhb/PnzxcxMTFCq9WKa665Ruzfv9/tOcrKysSsWbNEWFiYCAgIEOPGjRNnzpyRYW98V3V9DEAsXbrU1YZ97Rl33XWX6zMhMjJSpKWluUKKEOzn5nR5UGFfN53zvChqtVrExcWJiRMnioMHD7ru97U+loQQwvPjNERERERNxzUqRERE5LMYVIiIiMhnMagQERGRz2JQISIiIp/FoEJEREQ+i0GFiIiIfBaDChEREfksBhUi8itJSUl4/vnn5S6DiLyEQYWIanTnnXdiwoQJAIChQ4di9uzZXnvtZcuWISQkpMr2HTt24K9//avX6iAieankLoCIWpeKigpoNJpGPz4yMtKD1RCRr+OIChHV6c4778SmTZvwwgsvQJIkSJKEU6dOAQAOHTqEMWPGwGAwIDo6GlOmTEFOTo7rsUOHDsWsWbMwZ84cREREYMSIEQCA5557Dt27d4der0dCQgLuueceFBcXAwA2btyI6dOno7Cw0PV6CxYsAFB16ufMmTO44YYbYDAYEBwcjFtuuQXZ2dmu+xcsWICePXvivffeQ1JSEoxGI2677TYUFRW52nzyySfo3r07AgICEB4ejmuvvRYlJSXN1JtE1BAMKkRUpxdeeAGDBg3CX/7yF2RlZSErKwsJCQnIysrCkCFD0LNnT+zcuRNr165FdnY2brnlFrfHv/POO1CpVPj555/x+uuvAwAUCgVefPFFHDhwAO+88w5++OEHPPTQQwCAwYMH4/nnn0dwcLDr9ebOnVulLiEEJkyYgLy8PGzatAnr1q3D77//jltvvdWt3e+//47Vq1fjq6++wldffYVNmzZh0aJFAByXp580aRLuuusuHD58GBs3bsTEiRPBy6AR+QZO/RBRnYxGIzQaDQIDAxETE+PavmTJEvTu3RtPPfWUa9v//vc/JCQk4LfffkOnTp0AAB06dMDixYvdnvPS9S7t2rXD448/jpkzZ+LVV1+FRqOB0WiEJElur3e59evXY9++fTh58iQSEhIAAO+99x66deuGHTt2oF+/fgAAu92OZcuWISgoCAAwZcoUfP/993jyySeRlZUFq9WKiRMnIjExEQDQvXv3JvQWEXkSR1SIqNF27dqFDRs2wGAwuG5dunQB4BjFcOrbt2+Vx27YsAEjRoxAfHw8goKCMHXqVOTm5jZoyuXw4cNISEhwhRQASE5ORkhICA4fPuzalpSU5AopABAbG4sLFy4AAHr06IG0tDR0794dN998M958803k5+fXvxOIqFkxqBBRo9ntdowfPx579+51ux07dgzXXHONq51er3d73OnTpzFmzBikpKTg008/xa5du/DKK68AACwWS71fXwgBSZLq3K5Wq93ulyQJdrsdAKBUKrFu3TqsWbMGycnJeOmll9C5c2ecPHmy3nUQUfNhUCGietFoNLDZbG7bevfujYMHDyIpKQkdOnRwu10eTi61c+dOWK1WPPvssxg4cCA6deqEzMzMOl/vcsnJyThz5gwyMjJc2w4dOoTCwkJ07dq13vsmSRKuvPJKLFy4EHv27IFGo8GqVavq/Xgiaj4MKkRUL0lJSfjll19w6tQp5OTkwG63495770VeXh4mTZqE7du348SJE/juu+9w11131Roy2rdvD6vVipdeegknTpzAe++9h9dee63K6xUXF+P7779HTk4OSktLqzzPtddei9TUVEyePBm7d+/G9u3bMXXqVAwZMqTa6abq/PLLL3jqqaewc+dOnDlzBp999hkuXrzYoKBDRM2HQYWI6mXu3LlQKpVITk5GZGQkzpw5g7i4OPz888+w2WwYNWoUUlJS8MADD8BoNEKhqPnjpWfPnnjuuefwn//8BykpKfjggw+Qnp7u1mbw4MGYMWMGbr31VkRGRlZZjAs4RkJWr16N0NBQXHPNNbj22mtxxRVXYOXKlfXer+DgYPz4448YM2YMOnXqhH/+85949tlnMXr06Pp3DhE1G0nwGDwiIiLyURxRISIiIp/FoEJEREQ+i0GFiIiIfBaDChEREfksBhUiIiLyWQwqRERE5LMYVIiIiMhnMagQERGRz2JQISIiIp/FoEJEREQ+i0GFiIiIfBaDChEREfms/wdhYdZD+aKnuAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ploting loss evolution\n",
    "plt.plot(loss_eval)\n",
    "plt.title(f\"Loss evolution for {epochs} epochs, dataset size: {len(dataset)}\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation and evaluation\n",
    "idx = torch.randint(0, len(dataset) - 1, (1,))\n",
    "audio_input, video_input, context_input, target = dataset[idx]\n",
    "generated_sequence = model.generate(\n",
    "    audio_input, video_input, context_input, start_token_id, end_token_id\n",
    ")\n",
    "print(f\"Generated sequence: {generated_sequence}\")\n",
    "print(f\"Target: {target}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
